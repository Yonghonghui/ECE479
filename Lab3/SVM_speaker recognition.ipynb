{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b747de",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Speaker Classification using SVM #################\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f2149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Feature Extraction\n",
    "def extract_features(file_path, mfcc=True, chroma=True, mel=True, sr=22050):\n",
    "    audio_data, _ = librosa.load(file_path, sr=sr)\n",
    "    features = []\n",
    "    if mfcc:\n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sr)\n",
    "        features.extend(np.mean(mfccs, axis=1))\n",
    "    if chroma:\n",
    "        chroma = librosa.feature.chroma_stft(y=audio_data, sr=sr)\n",
    "        features.extend(np.mean(chroma, axis=1))\n",
    "    if mel:\n",
    "        mel = librosa.feature.melspectrogram(y=audio_data, sr=sr)\n",
    "        features.extend(np.mean(mel, axis=1))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e21a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio files and extract features\n",
    "def load_data(file_paths,sr):\n",
    "    X = []\n",
    "    y = []\n",
    "    for file_path in file_paths:\n",
    "        features = extract_features(file_path,sr)\n",
    "        X.append(features)\n",
    "        # Assume file name format is \"<speaker_id>_<other_info>.wav\"\n",
    "#         print(file_path)\n",
    "        label = file_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e94b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Function to collect paths of all .wav files in a directory\n",
    "def collect_audio_paths(directory):\n",
    "    audio_paths = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            audio_paths.append(os.path.join(root, file))\n",
    "    return audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53382963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (81, 160)\n",
      "[[-5.24045471e+02  5.64239349e+01 -1.28164454e+01 ...  2.56934451e-09\n",
      "   1.29407440e-09  1.21273241e-10]\n",
      " [-4.00629059e+02  9.98563309e+01 -2.24793739e+01 ...  3.50395934e-09\n",
      "   1.96301198e-09  1.71816200e-10]\n",
      " [-3.86967804e+02  8.67731247e+01 -2.87876492e+01 ...  3.45428663e-09\n",
      "   1.90756988e-09  1.59032662e-10]\n",
      " ...\n",
      " [-4.15776093e+02  9.71693039e+01 -5.00135803e+01 ...  2.41103604e-09\n",
      "   1.49688217e-09  3.46428414e-10]\n",
      " [-4.09536560e+02  9.68211746e+01 -3.64263458e+01 ...  2.01503658e-09\n",
      "   1.20051968e-09  1.13576856e-10]\n",
      " [-4.48099243e+02  7.34625473e+01 -2.37659512e+01 ...  2.01631378e-09\n",
      "   1.11475174e-09  9.93241045e-11]]\n",
      "(64, 160)\n",
      "(64,)\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "# Load audio files and corresponding labels\n",
    "# Directory containing .wav files\n",
    "audio_directory = \"audio_files/\"\n",
    "# Sampling Rate\n",
    "sr= 22050\n",
    "\n",
    "class_names = [\"cyhh\",\"haoyu\",\"stranger\"]\n",
    "# Collect paths of .wav files\n",
    "file_paths = collect_audio_paths(audio_directory)\n",
    "\n",
    "X, y = load_data(file_paths,sr)\n",
    "# print(y)\n",
    "\n",
    "# print(y_encoded)\n",
    "# print(\"X:\",X)\n",
    "# print(\"y:\",y)\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(X)\n",
    "# X=X.reshape((X.shape[0],X.shape[1],1))\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "input_shape=X_train.shape[1]\n",
    "print(input_shape)\n",
    "\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59be5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Scaling\n",
    "# X_scaled=[]\n",
    "# for i in range(X.shape[0]):\n",
    "#     scaler = StandardScaler()\n",
    "#     x_scaled = scaler.fit_transform(X[i])\n",
    "#     X_scaled.append(x_scaled)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9755ab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Train a Binary Classification Model (SVM Example)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f1e1427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluation (Optional)\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c60cba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Speaker: cyhh\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Inference\n",
    "# Assuming you have a new audio sample stored in the variable new_audio_file\n",
    "new_audio_features = extract_features(\"test_audio/haoyu_audio_4.wav\")\n",
    "new_audio_features_scaled = scaler.transform([new_audio_features])\n",
    "# print(new_audio_features_scaled)\n",
    "predicted_label = svm_clf.predict(new_audio_features_scaled)\n",
    "if predicted_label[0] in class_names:\n",
    "    print(\"Predicted Speaker:\", predicted_label[0])\n",
    "else:\n",
    "    print(\"Predicted Speaker: Stranger\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aec6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
