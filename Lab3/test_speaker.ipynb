{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a5e8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "153\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[2.5620062e-05 9.9997437e-01 1.1508359e-08]]\n",
      "Predicted label: haoyu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras import layers, models, utils\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract MFCC features from audio files\n",
    "def extract_features(file_path, mfcc=True, chroma=True, mel=True,sr=22050):\n",
    "    audio_data, _ = librosa.load(file_path)  # Load audio data directly without a context manager\n",
    "    features = []\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13), axis=1)\n",
    "        features.extend(mfccs)\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=audio_data, sr=sr), axis=1)\n",
    "        features.extend(chroma)\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=audio_data, sr=sr), axis=1)\n",
    "        features.extend(mel)\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    sr=22050\n",
    "    class_names = [\"cyhh\",\"haoyu\",\"stranger\"]\n",
    "    # Load the model\n",
    "    model = tf.keras.models.load_model('speaker_recognition_model')\n",
    "    # preprocessing\n",
    "    test_feature= extract_features(\"test_audio/test.wav\", mfcc=True, chroma=True, mel=True,sr=22050)\n",
    "    # test_feature= extract_features(\"audio_files/haoyu_audio_70.wav\", mfcc=True, chroma=True, mel=True,sr=22050)\n",
    "    print(len(test_feature))\n",
    "    test_feature= np.array(test_feature)\n",
    "    # print(test_feature.shape)\n",
    "    test_feature= test_feature.reshape(1,153,1)\n",
    "    # print(test_feature.shape)\n",
    "\n",
    "    # Make prediction\n",
    "\n",
    "    predictions = model.predict(test_feature)\n",
    "    print(predictions)\n",
    "    # Post-process predictions (e.g., choose the class with the highest probability)\n",
    "    predicted_label = np.argmax(predictions)\n",
    "\n",
    "    print(\"Predicted label:\", class_names[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938340f8-e150-40a9-ab82-c0117eaa8ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
